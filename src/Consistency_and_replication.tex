\chapter{Consistency and Replication}
To make a system more reliable and enhance performance usually data is replicated, it's pretty easy to see that the replication procedure creates a couple of very important issues, first and foremost the consisteny of the data, we may have different copies of the same resource inside the network and not all of them might contain the same information. Secondly we must consider the fact that we might have conflicts while handling operations (read-write and write-write conflicts).

To these issues we might use Data-centric consistency models, the idea is that we have a contract between data store and processes in which the data store specifies precisely what the result of read and write operations are in the presence of concurrency.

If we want to grant continuous consistency we want first to define a degree of consistency that we want to maintain, for example: replicas may differ in their numerical value or replicas may differ in their relative staleness. To define consistency more formally the consistency unit (conit) was created and it specifies the data unit over which consistency is to be measured.

To solve the operational conflicts we introduce consistent ordering of operations, which can be sequential or causal.

When using sequential consistency we want the result of any execution to be the same as if all of the operations on the data store were executed in some sequential order, and the operations of each individual process appear in this sequence.

When using causal consistncy all the writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order by different processes.

Another really interesting technique to make operations consistent is the use of grouping, we don't care that the individual results are immediately known to other processes. We care that the effect of a series of them is known though. This makes the access to locks sequentially consistent.

Until now we have talked about consistency models, a consistency model describes what can be expected with respect to that set when multiple processes operate on the same data. Coherence is a property, linked to consistency, that describes what can be expected to hold for only a single data item, if we consider data item replicated it is coherent if the replications abide to the rules of the consistency model. There is also a theorem that states that: if no updates take place for a long time all replicas will gradually become consistent (Eventual consistency).

It's interesting to note that ensuring strong consistency is expensive and may only be guaranteed when processes use mechanisms such as transactions and synchronization variables. Therefore we usually offer some watered down guarantees that might be enough for just one of the agents or might hold under particular conditions (like eventual consistency). A couple examples of client-centric (weaker) consistency models are:
\begin{itemize}
    \item Monotonic reads - if a process reads a value, that value will either have the same or a newer value.
    \item Monotonic writes - a write by a process on a value x is completed before any successive write operation on x by the same process. The order of the writes is preserved and FIFO.
    \item Read your writes - The effect of any write by a process on a value will always be seen by a successive read operation on that value by the same process.
    \item writes follow reads - A write operation by a process on a value x following a previous read operation on x by the same process is guaranteed to take place on the same or a newer value of x. Therefore any successive write operation by a process on a value x will be performed on a copy of x that is up to date.
\end{itemize}
Consistency protocols describe an implementation of a specific consistency model.

Now we move to the problem of replication, whenever implementing a replication system it should also be accompanied by a replica management system, which decides where, when and by whom replicas should be placed, and subsequently which mechanisms to use for keeping the replicas consistent.

If we take into consideration the standard client-server model we can say that when it comes to replicas we have different types of them:
\begin{itemize}
    \item Permanent replica - the initial set.
    \item Server initiated replica - replicas that exist to enhance perfomance and are created by the server.
    \item Client initiated replica - client cache.
\end{itemize}
It's also important to consider how to manage the replication process, should the copies be updated or should they be considered invalid and the owner notified? We have three different approaches to the problem: Propagation only, Passive replication (we transfer data from one copy to another), Active replication (we propagate the update operation to other copies).

The updates can be pushed by the server, independently from the client asking the resource or pulled by the client, which can ask for an update to be made on a resource. We can choose to stick with one of the two approaches or we can go crazy and move to Leases, which consists in dynamically changing the replication strategy based on different parameters: age of the lease, number of lease renewals, state of the server, etc...
